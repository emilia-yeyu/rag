# backend/embedding/adapter.py
import os
import importlib
from typing import Any, Optional, TYPE_CHECKING, Dict, Set, Callable, List

# ä½¿ç”¨ TYPE_CHECKING æ¥é¿å…å¾ªç¯å¯¼å…¥ï¼Œå¹¶å…è®¸ç±»å‹æç¤º
if TYPE_CHECKING:
    from langchain_core.embeddings import Embeddings

class EmbeddingAdapterError(Exception):
    """åµŒå…¥æ¨¡å‹é€‚é…å™¨ç›¸å…³çš„è‡ªå®šä¹‰é”™è¯¯ã€‚"""
    pass

class EmbeddingAdapter:
    """
    åµŒå…¥æ¨¡å‹é€‚é…å™¨å·¥å…·ç±»ï¼Œæä¾›é™æ€æ–¹æ³•ç”¨äºåˆ›å»ºLangChain Embeddingå®ä¾‹ã€‚
    æŒ‰éœ€åŠ è½½ç›¸åº”çš„ä¾èµ–åº“ã€‚
    """
    
    # æ”¯æŒçš„åµŒå…¥æ¨¡å‹æä¾›å•†åˆ—è¡¨
    SUPPORTED_PROVIDERS: Set[str] = {
        "openai",
        "dashscope",
        "google",
        "bge",  # æ·»åŠ  bge æ”¯æŒ
    }
    
    # æä¾›å•†åˆ°æ„å»ºæ–¹æ³•åç§°çš„æ˜ å°„
    _PROVIDER_BUILDERS: Dict[str, str] = {
        "openai": "_build_openai_embedding",
        "dashscope": "_build_dashscope_embedding",
        "google": "_build_google_embedding",
        "bge": "_build_bge_embedding",  # æ·»åŠ  bge æ„å»ºæ–¹æ³•
    }

    @staticmethod
    def get_embedding(provider: str, model_name: Optional[str] = None) -> 'Embeddings':
        """
        è·å–æŒ‡å®šæä¾›å•†å’Œæ¨¡å‹çš„ LangChain Embedding å®ä¾‹ã€‚

        Args:
            provider: åµŒå…¥æ¨¡å‹æä¾›å•†åç§° (ä¾‹å¦‚ "openai", "dashscope", "google")ã€‚
            model_name: å…·ä½“çš„æ¨¡å‹åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æ¨¡å‹
                        (ä¾‹å¦‚ "text-embedding-3-small", "text-embedding-v1", "embedding-001")ã€‚

        Returns:
            ä¸€ä¸ªé…ç½®å¥½çš„ LangChain Embeddings å®ä¾‹ã€‚

        Raises:
            EmbeddingAdapterError: å¦‚æœæä¾›å•†ä¸æ”¯æŒã€ç¼ºå°‘ API å¯†é’¥ã€æ— æ³•åŠ è½½ä¾èµ–æˆ–å®ä¾‹åŒ–å¤±è´¥ã€‚
            ImportError: å¦‚æœæ— æ³•å¯¼å…¥æ‰€éœ€çš„ LangChain åº“ã€‚
        """
        if not provider:
             raise EmbeddingAdapterError("å¿…é¡»æä¾› Embedding provider åç§°ã€‚")

        provider = provider.lower() # ç»Ÿä¸€è½¬ä¸ºå°å†™å¤„ç†
        
        # æ£€æŸ¥æä¾›å•†æ˜¯å¦æ”¯æŒ
        if provider not in EmbeddingAdapter.SUPPORTED_PROVIDERS:
            supported_list = ', '.join([f'"{p}"' for p in sorted(EmbeddingAdapter.SUPPORTED_PROVIDERS)])
            raise EmbeddingAdapterError(f"ä¸æ”¯æŒçš„åµŒå…¥æ¨¡å‹æä¾›å•†: '{provider}'ã€‚æ”¯æŒçš„æä¾›å•†: {supported_list}")
        
        # ä½¿ç”¨æ˜ å°„è·å–æ„å»ºæ–¹æ³•
        if provider not in EmbeddingAdapter._PROVIDER_BUILDERS:
            # è¿™ç§æƒ…å†µç†è®ºä¸Šä¸åº”è¯¥å‘ç”Ÿï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»æ£€æŸ¥äº†SUPPORTED_PROVIDERS
            raise EmbeddingAdapterError(f"å†…éƒ¨é”™è¯¯: æä¾›å•† '{provider}' åœ¨æ”¯æŒåˆ—è¡¨ä¸­ä½†ç¼ºå°‘æ„å»ºæ–¹æ³•")
            
        # è·å–å¯¹åº”çš„æ„å»ºæ–¹æ³•åç§°
        builder_name = EmbeddingAdapter._PROVIDER_BUILDERS[provider]
        
        # åŠ¨æ€è·å–å¹¶è°ƒç”¨æ„å»ºæ–¹æ³•
        try:
            # ä½¿ç”¨getattrè·å–ç±»çš„é™æ€æ–¹æ³•
            builder_method = getattr(EmbeddingAdapter, builder_name)
            # è°ƒç”¨æ„å»ºæ–¹æ³•
            return builder_method(model_name)
        except AttributeError:
            raise EmbeddingAdapterError(f"å†…éƒ¨é”™è¯¯: æœªæ‰¾åˆ°æ„å»ºæ–¹æ³• '{builder_name}'")

    @staticmethod
    def _lazy_import(module_name: str, class_name: str) -> Any:
        """æŒ‰éœ€å¯¼å…¥æ¨¡å—å’Œç±»ã€‚"""
        try:
            module = importlib.import_module(module_name)
            return getattr(module, class_name)
        except ImportError:
            raise ImportError(f"æ— æ³•å¯¼å…¥ '{class_name}' ä» '{module_name}'ã€‚è¯·ç¡®ä¿å®‰è£…äº†å¿…è¦çš„åº“ (ä¾‹å¦‚ langchain-openai)ã€‚")
        except AttributeError:
             raise EmbeddingAdapterError(f"åœ¨æ¨¡å— '{module_name}' ä¸­æœªæ‰¾åˆ°ç±» '{class_name}'ã€‚")

    @staticmethod
    def _build_openai_embedding(model_name: Optional[str] = None) -> 'Embeddings':
        """
        æ„å»º OpenAI çš„ LangChain Embedding å®ä¾‹ã€‚
        æ”¯æŒé€šè¿‡ç¯å¢ƒå˜é‡è‡ªå®šä¹‰ base_urlã€‚
        
        Args:
            model_name: OpenAIåµŒå…¥æ¨¡å‹åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æ¨¡å‹"text-embedding-3-small"
        
        Returns:
            é…ç½®å¥½çš„OpenAIåµŒå…¥æ¨¡å‹å®ä¾‹
        """
        # 1. æŒ‰éœ€å¯¼å…¥
        OpenAIEmbeddings = EmbeddingAdapter._lazy_import('langchain_openai', 'OpenAIEmbeddings')

        # 2. è·å– API å¯†é’¥
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise EmbeddingAdapterError("æ— æ³•æ„å»º OpenAI Embedding: ç¯å¢ƒå˜é‡ 'OPENAI_API_KEY' æœªè®¾ç½®æˆ–ä¸ºç©ºã€‚")
          
        # 3. æ£€æŸ¥æ˜¯å¦æœ‰è‡ªå®šä¹‰çš„ base_url
        base_url = os.getenv("OPENAI_BASE_URL")
        
        # 4. å®ä¾‹åŒ–
        try:
            kwargs = {
                "model": model_name if model_name else "text-embedding-3-small",
                "openai_api_key": api_key,
            }
            
            # å¦‚æœè®¾ç½®äº†è‡ªå®šä¹‰ base_urlï¼Œåˆ™æ·»åŠ åˆ°å‚æ•°ä¸­
            if base_url:
                kwargs["base_url"] = base_url
                print(f"ä½¿ç”¨è‡ªå®šä¹‰ OpenAI API ç«¯ç‚¹: {base_url}")
            
            embedding = OpenAIEmbeddings(**kwargs)
            
            print(f"æˆåŠŸæ„å»º OpenAI Embedding: æ¨¡å‹='{kwargs['model']}'")
            return embedding
        except Exception as e:
            raise EmbeddingAdapterError(f"å®ä¾‹åŒ– OpenAI Embedding (æ¨¡å‹: {model_name}) æ—¶å‡ºé”™: {e}")
            
    @staticmethod
    def _build_dashscope_embedding(model_name: Optional[str] = None) -> 'Embeddings':
        """
        æ„å»º é˜¿é‡Œäº‘ç™¾ç‚¼(DashScope) çš„ LangChain Embedding å®ä¾‹ã€‚
        
        Args:
            model_name: DashScopeåµŒå…¥æ¨¡å‹åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æ¨¡å‹"text-embedding-v1"
        
        Returns:
            é…ç½®å¥½çš„DashScopeåµŒå…¥æ¨¡å‹å®ä¾‹
        """
        # 1. æŒ‰éœ€å¯¼å…¥
        DashScopeEmbeddings = EmbeddingAdapter._lazy_import('langchain_community.embeddings', 'DashScopeEmbeddings')

        # 2. è·å– API å¯†é’¥
        api_key = os.getenv("DASHSCOPE_API_KEY")
        if not api_key:
            raise EmbeddingAdapterError("æ— æ³•æ„å»º DashScope Embedding: ç¯å¢ƒå˜é‡ 'DASHSCOPE_API_KEY' æœªè®¾ç½®æˆ–ä¸ºç©ºã€‚")
        
        # 3. å®ä¾‹åŒ–
        try:
            model = model_name if model_name else "text-embedding-v3"
            embedding = DashScopeEmbeddings(
                model=model,
                dashscope_api_key=api_key
            )
            
            print(f"æˆåŠŸæ„å»º DashScope Embedding: æ¨¡å‹='{model}'")
            return embedding
        except Exception as e:
            raise EmbeddingAdapterError(f"å®ä¾‹åŒ– DashScope Embedding (æ¨¡å‹: {model_name}) æ—¶å‡ºé”™: {e}")
            
    @staticmethod
    def _build_google_embedding(model_name: Optional[str] = None) -> 'Embeddings':
        """
        æ„å»º Google Generative AI çš„ LangChain Embedding å®ä¾‹ã€‚
        
        Args:
            model_name: GoogleåµŒå…¥æ¨¡å‹åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æ¨¡å‹"embedding-001"
        
        Returns:
            é…ç½®å¥½çš„GoogleåµŒå…¥æ¨¡å‹å®ä¾‹
        """
        # 1. æŒ‰éœ€å¯¼å…¥
        GoogleGenerativeAIEmbeddings = EmbeddingAdapter._lazy_import('langchain_google_genai', 'GoogleGenerativeAIEmbeddings')

        # 2. è·å– API å¯†é’¥
        api_key = os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise EmbeddingAdapterError("æ— æ³•æ„å»º Google Embedding: ç¯å¢ƒå˜é‡ 'GOOGLE_API_KEY' æœªè®¾ç½®æˆ–ä¸ºç©ºã€‚")
        
        # 3. å®ä¾‹åŒ–
        try:
            model = model_name if model_name else "text-embedding-004"
            embedding = GoogleGenerativeAIEmbeddings(
                model=model,
                google_api_key=api_key
            )
            
            print(f"æˆåŠŸæ„å»º Google Embedding: æ¨¡å‹='{model}'")
            return embedding
        except Exception as e:
            raise EmbeddingAdapterError(f"å®ä¾‹åŒ– Google Embedding (æ¨¡å‹: {model_name}) æ—¶å‡ºé”™: {e}")

    @staticmethod
    def _get_local_model_path(model_name: str) -> Optional[str]:
        """
        è·å–æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›Noneã€‚
        
        Args:
            model_name: æ¨¡å‹åç§°ï¼Œä¾‹å¦‚ "BAAI/bge-large-zh-v1.5"
        
        Returns:
            æœ¬åœ°æ¨¡å‹è·¯å¾„æˆ–None
        """
        # å°†huggingfaceæ¨¡å‹åç§°è½¬æ¢ä¸ºæœ¬åœ°ç¼“å­˜ç›®å½•åç§°
        cache_name = model_name.replace("/", "--")
        cache_name = f"models--{cache_name}"
        
        # è·å–é¡¹ç›®æ ¹ç›®å½•å¹¶æ„å»ºæ¨¡å‹è·¯å¾„
        script_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  # å›åˆ° RAG ç›®å½•
        model_base_path = os.path.join(script_dir, "models", "embeddings", cache_name)
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨mainå¼•ç”¨æ–‡ä»¶
        main_ref_path = os.path.join(model_base_path, "refs", "main")
        if os.path.exists(main_ref_path):
            # è¯»å–mainå¼•ç”¨æŒ‡å‘çš„snapshot
            try:
                with open(main_ref_path, 'r') as f:
                    snapshot_hash = f.read().strip()
                
                # æ„å»ºå®Œæ•´çš„snapshotè·¯å¾„
                snapshot_path = os.path.join(model_base_path, "snapshots", snapshot_hash)
                
                # éªŒè¯snapshotè·¯å¾„å­˜åœ¨ä¸”åŒ…å«å¿…è¦çš„é…ç½®æ–‡ä»¶
                if os.path.exists(snapshot_path) and os.path.exists(os.path.join(snapshot_path, "config.json")):
                    return snapshot_path
            except Exception:
                pass
        
        return None

    @staticmethod
    def _build_bge_embedding(model_name: Optional[str] = None) -> 'Embeddings':
        """
        æ„å»º BGE (BAAI General Embedding) çš„ LangChain Embedding å®ä¾‹ã€‚
        ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨ HuggingFace åœ¨çº¿æ¨¡å‹ã€‚
        
        Args:
            model_name: BGEåµŒå…¥æ¨¡å‹åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æ¨¡å‹"BAAI/bge-large-zh-v1.5"
        
        Returns:
            é…ç½®å¥½çš„BGEåµŒå…¥æ¨¡å‹å®ä¾‹
        """
        # 1. æŒ‰éœ€å¯¼å…¥
        HuggingFaceEmbeddings = EmbeddingAdapter._lazy_import('langchain_huggingface', 'HuggingFaceEmbeddings')

        # 2. è®¾ç½®æ¨¡å‹åç§°
        model = model_name if model_name else "BAAI/bge-large-zh-v1.5"
        
        # 3. å°è¯•è·å–æœ¬åœ°æ¨¡å‹è·¯å¾„
        local_model_path = EmbeddingAdapter._get_local_model_path(model)
        actual_model_path = local_model_path if local_model_path else model
        ## 3. å°è¯•è·å–æœ¬åœ°æ¨¡å‹è·¯å¾„
        #local_model_path = EmbeddingAdapter._get_local_model_path(model)
        #actual_model_path = local_model_path if local_model_path else model

        # è·å–é¡¹ç›®æ ¹ç›®å½•å¹¶è®¾ç½®æ¨¡å‹ç¼“å­˜ç›®å½•
        script_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  # å›åˆ° RAG ç›®å½•
        cache_dir = os.path.join(script_dir, "models", "embeddings")
        os.makedirs(cache_dir, exist_ok=True)
        
        # 4. å®ä¾‹åŒ–
        try:
            # BGE æ¨¡å‹çš„æ¨èé…ç½®
            encode_kwargs = {
                'normalize_embeddings': True,  # BGE æ¨èå½’ä¸€åŒ–
                'batch_size': 32,  # åˆé€‚çš„æ‰¹å¤„ç†å¤§å°
            }
            
            # æ¨¡å‹é…ç½®
            model_kwargs = {
                'device': 'cpu',  # å¯ä»¥æ ¹æ®éœ€è¦æ”¹ä¸º 'cuda'
                'trust_remote_code': True,  # BGE æ¨¡å‹éœ€è¦æ­¤é€‰é¡¹
            }
            
            embedding = HuggingFaceEmbeddings(
                model_name=actual_model_path,#model
                model_kwargs=model_kwargs,
                encode_kwargs=encode_kwargs,
                show_progress=True,  # æ˜¾ç¤ºä¸‹è½½è¿›åº¦
                cache_folder=cache_dir if not local_model_path else None,  # æœ¬åœ°æ¨¡å‹ä¸éœ€è¦é¢å¤–ç¼“å­˜
            )
            
            if local_model_path:
                print(f"âœ… æˆåŠŸæ„å»º BGE Embedding (æœ¬åœ°æ¨¡å‹): è·¯å¾„='{local_model_path}'")
            else:
                print(f"âœ… æˆåŠŸæ„å»º BGE Embedding (åœ¨çº¿æ¨¡å‹): æ¨¡å‹='{model}'")
                print(f"ğŸ“ æ¨¡å‹ç¼“å­˜ç›®å½•: {cache_dir}")
                print(f"æ³¨æ„: é¦–æ¬¡ä½¿ç”¨ä¼šä¸‹è½½æ¨¡å‹åˆ°æŒ‡å®šç›®å½•ï¼Œè¯·è€å¿ƒç­‰å¾…")
            
            return embedding
        except Exception as e:
            error_msg = f"å®ä¾‹åŒ– BGE Embedding æ—¶å‡ºé”™: {e}"
            if local_model_path:
                error_msg += f"\næœ¬åœ°æ¨¡å‹è·¯å¾„: {local_model_path}"
            else:
                error_msg += f"\nåœ¨çº¿æ¨¡å‹: {model}"
            raise EmbeddingAdapterError(error_msg)




"""     @staticmethod
    def _get_local_model_path(model_name: str) -> Optional[str]:
        '''
        è·å–æœ¬åœ°æ¨¡å‹è·¯å¾„ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å›Noneã€‚
        
        Args:
            model_name: æ¨¡å‹åç§°ï¼Œä¾‹å¦‚ "BAAI/bge-large-zh-v1.5"
        
        Returns:
            æœ¬åœ°æ¨¡å‹è·¯å¾„æˆ–None
        '''
        # å°†huggingfaceæ¨¡å‹åç§°è½¬æ¢ä¸ºæœ¬åœ°ç¼“å­˜ç›®å½•åç§°
        cache_name = model_name.replace("/", "--")
        cache_name = f"models--{cache_name}"
        
        # è·å–é¡¹ç›®æ ¹ç›®å½•å¹¶æ„å»ºæ¨¡å‹è·¯å¾„
        script_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  # å›åˆ° RAG ç›®å½•
        model_base_path = os.path.join(script_dir, "models", "embeddings", cache_name)
        
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨mainå¼•ç”¨æ–‡ä»¶
        main_ref_path = os.path.join(model_base_path, "refs", "main")
        if os.path.exists(main_ref_path):
            # è¯»å–mainå¼•ç”¨æŒ‡å‘çš„snapshot
            try:
                with open(main_ref_path, 'r') as f:
                    snapshot_hash = f.read().strip()
                
                # æ„å»ºå®Œæ•´çš„snapshotè·¯å¾„
                snapshot_path = os.path.join(model_base_path, "snapshots", snapshot_hash)
                
                # éªŒè¯snapshotè·¯å¾„å­˜åœ¨ä¸”åŒ…å«å¿…è¦çš„é…ç½®æ–‡ä»¶
                if os.path.exists(snapshot_path) and os.path.exists(os.path.join(snapshot_path, "config.json")):
                    return snapshot_path
            except Exception:
                pass
        
        return None

    @staticmethod
    def _build_bge_embedding(model_name: Optional[str] = None) -> 'Embeddings':
        '''
        æ„å»º BGE (BAAI General Embedding) çš„ LangChain Embedding å®ä¾‹ã€‚
        ä¼˜å…ˆä½¿ç”¨æœ¬åœ°å¾®è°ƒæ¨¡å‹ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨ HuggingFace åœ¨çº¿æ¨¡å‹ã€‚
        
        Args:
            model_name: BGEåµŒå…¥æ¨¡å‹åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æ¨¡å‹"BAAI/bge-large-zh-v1.5"
        
        Returns:
            é…ç½®å¥½çš„BGEåµŒå…¥æ¨¡å‹å®ä¾‹
        '''
        # 1. æŒ‰éœ€å¯¼å…¥
        HuggingFaceEmbeddings = EmbeddingAdapter._lazy_import('langchain_huggingface', 'HuggingFaceEmbeddings')

        # 2. è®¾ç½®æ¨¡å‹åç§°
        model = model_name if model_name else "BAAI/bge-large-zh-v1.5"
        
        # 3. ä¼˜å…ˆæ£€æŸ¥å¾®è°ƒæ¨¡å‹è·¯å¾„
        script_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  # å›åˆ° RAG ç›®å½•
        fine_tuned_model_path = os.path.join(script_dir, "models", "ft_BAAI_bge-large-zh-v1.5")
        
        # æ£€æŸ¥å¾®è°ƒæ¨¡å‹æ˜¯å¦å­˜åœ¨
        if os.path.exists(fine_tuned_model_path) and os.path.exists(os.path.join(fine_tuned_model_path, "config.json")):
            actual_model_path = fine_tuned_model_path
            is_fine_tuned = True
            print(f"ğŸ¯ å‘ç°å¾®è°ƒæ¨¡å‹: {fine_tuned_model_path}")
        else:
            # é™çº§åˆ°åŸæ¥çš„é€»è¾‘ï¼šå°è¯•è·å–æœ¬åœ°æ¨¡å‹è·¯å¾„
            local_model_path = EmbeddingAdapter._get_local_model_path(model)
            actual_model_path = local_model_path if local_model_path else model
            is_fine_tuned = False
        
        # è®¾ç½®æ¨¡å‹ç¼“å­˜ç›®å½•ï¼ˆå¾®è°ƒæ¨¡å‹ä¸éœ€è¦ç¼“å­˜ï¼‰
        cache_dir = os.path.join(script_dir, "models", "embeddings")
        if not is_fine_tuned:
            os.makedirs(cache_dir, exist_ok=True)
        
        # 4. å®ä¾‹åŒ–
        try:
            # BGE æ¨¡å‹çš„æ¨èé…ç½®
            encode_kwargs = {
                'normalize_embeddings': True,  # BGE æ¨èå½’ä¸€åŒ–
                'batch_size': 32,  # åˆé€‚çš„æ‰¹å¤„ç†å¤§å°
            }
            
            # æ¨¡å‹é…ç½®
            model_kwargs = {
                'device': 'cpu',  # å¯ä»¥æ ¹æ®éœ€è¦æ”¹ä¸º 'cuda'
                'trust_remote_code': True,  # BGE æ¨¡å‹éœ€è¦æ­¤é€‰é¡¹
            }
            
            embedding = HuggingFaceEmbeddings(
                model_name=actual_model_path,
                model_kwargs=model_kwargs,
                encode_kwargs=encode_kwargs,
                show_progress=True,  # æ˜¾ç¤ºä¸‹è½½è¿›åº¦
                cache_folder=cache_dir if not is_fine_tuned else None,  # å¾®è°ƒæ¨¡å‹ä¸éœ€è¦é¢å¤–ç¼“å­˜
            )
            
            if is_fine_tuned:
                print(f"âœ… æˆåŠŸæ„å»º BGE Embedding (å¾®è°ƒæ¨¡å‹): è·¯å¾„='{actual_model_path}'")
                print(f"ğŸ”¥ ä½¿ç”¨æ‚¨è®­ç»ƒçš„å¾®è°ƒæ¨¡å‹ï¼")
            elif actual_model_path != model:
                print(f"âœ… æˆåŠŸæ„å»º BGE Embedding (æœ¬åœ°æ¨¡å‹): è·¯å¾„='{actual_model_path}'")
            else:
                print(f"âœ… æˆåŠŸæ„å»º BGE Embedding (åœ¨çº¿æ¨¡å‹): æ¨¡å‹='{model}'")
                print(f"ğŸ“ æ¨¡å‹ç¼“å­˜ç›®å½•: {cache_dir}")
                print(f"æ³¨æ„: é¦–æ¬¡ä½¿ç”¨ä¼šä¸‹è½½æ¨¡å‹åˆ°æŒ‡å®šç›®å½•ï¼Œè¯·è€å¿ƒç­‰å¾…")
            
            return embedding
        except Exception as e:
            error_msg = f"å®ä¾‹åŒ– BGE Embedding æ—¶å‡ºé”™: {e}"
            if is_fine_tuned:
                error_msg += f"\nå¾®è°ƒæ¨¡å‹è·¯å¾„: {actual_model_path}"
            elif actual_model_path != model:
                error_msg += f"\næœ¬åœ°æ¨¡å‹è·¯å¾„: {actual_model_path}"
            else:
                error_msg += f"\nåœ¨çº¿æ¨¡å‹: {model}"
            raise EmbeddingAdapterError(error_msg) """
