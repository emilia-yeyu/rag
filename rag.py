#!/usr/bin/env python3
"""
åŸºäº1.txtçš„ç®€å•RAGç³»ç»Ÿ
ä½¿ç”¨ç°æœ‰ç»„ä»¶æ„å»ºçš„å•æ–‡ä»¶è§£å†³æ–¹æ¡ˆ
"""

import os
os.environ['TRANSFORMERS_OFFLINE'] = '0'
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
import time
import asyncio
import threading
from typing import Dict, Any, List
from pathlib import Path
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# å¯¼å…¥ç°æœ‰ç»„ä»¶
from document_loader.local_document_processor import LocalDocumentProcessor
from embedding.adapter import EmbeddingAdapter
# from embedding.reranker import AdaptiveReranker  # å·²ç¦ç”¨é‡æ’åº
from llm.adapter import LLMAdapter
from vector_store.vector_store import VectorStoreManager
from vector_store.bm25_vec import HybridRetriever
from vector_store.incremental_document_processor import IncrementalDocumentProcessor

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
# è·å–é¡¹ç›®æ ¹ç›®å½•çš„ .env æ–‡ä»¶è·¯å¾„

load_dotenv()


class SimpleRAG:
    """ç®€å•RAGç³»ç»Ÿ"""
    
    def __init__(self, document_path: str = "1.txt"):
        """åˆå§‹åŒ–RAGç³»ç»Ÿ"""
        # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œå°è¯•åœ¨è„šæœ¬æ‰€åœ¨ç›®å½•æŸ¥æ‰¾
        if not os.path.isabs(document_path):
            script_dir = os.path.dirname(os.path.abspath(__file__))
            full_path = os.path.join(script_dir, document_path)
            if os.path.exists(full_path):
                document_path = full_path
        
        self.document_path = document_path
        self._auto_update_thread = None
        self._stop_auto_update = threading.Event()
        
        print(f"ğŸš€ åˆå§‹åŒ–æ··åˆæ£€ç´¢RAGç³»ç»Ÿ...")
        print(f"ğŸ“ æ–‡æ¡£è·¯å¾„: {self.document_path}")
        print(f"ğŸ” æ£€ç´¢æ¨¡å¼: BGEå‘é‡æ£€ç´¢ + BM25å…³é”®è¯æ£€ç´¢ + RRFèåˆ")
        print(f"â° è‡ªåŠ¨æ›´æ–°: æ¯5åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡")
        
        # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å­˜åœ¨
        if not os.path.exists(document_path):
            raise FileNotFoundError(f"æ–‡æ¡£æ–‡ä»¶ä¸å­˜åœ¨: {document_path}")
        
        # åˆå§‹åŒ–ç»„ä»¶
        self._setup_components()
        self._build_knowledge_base()
        self._setup_rag_chain()
        
        # å¯åŠ¨æ—¶æ£€æŸ¥ä¸€æ¬¡æ›´æ–°
        if self.incremental_processor:
            print(f"ğŸ” å¯åŠ¨æ—¶æ£€æŸ¥æ–‡æ¡£æ›´æ–°...")
            try:
                result = self.update_documents()
                if result["status"] == "success" and result.get("total_processed", 0) > 0:
                    print(f"âœ… å¯åŠ¨æ—¶å‘ç°å¹¶å¤„ç†äº† {result['total_processed']} ä¸ªæ–‡æ¡£æ›´æ–°")
                elif result["status"] == "no_changes":
                    print(f"â„¹ï¸ å¯åŠ¨æ—¶æœªå‘ç°æ–‡æ¡£å˜æ›´")
            except Exception as e:
                print(f"âš ï¸ å¯åŠ¨æ—¶æ›´æ–°æ£€æŸ¥å¤±è´¥: {e}")
        
        # å¯åŠ¨è‡ªåŠ¨æ›´æ–°åå°çº¿ç¨‹
        if self.incremental_processor:
            self._start_auto_update_thread()
        
        print(f"âœ… RAGç³»ç»Ÿå°±ç»ªï¼")
    
    def _setup_components(self):
        """è®¾ç½®ç»„ä»¶"""
        # åµŒå…¥æ¨¡å‹ - ä½¿ç”¨å¼€æºå…è´¹çš„ bge-large-zh-v1.5
        self.embedding = EmbeddingAdapter.get_embedding("bge", "BAAI/bge-large-zh-v1.5")
        
        self.llm = LLMAdapter.get_llm("openai", "Qwen/Qwen2.5-7B-Instruct", temperature=0.1)
        # LLM - ä½¿ç”¨æœ¬åœ°æ¨¡å‹
        #self.llm = LLMAdapter.get_llm("local", "models/qwen2.5-1.5b-instruct", temperature=0.1)
        
        # å‘é‡å­˜å‚¨ï¼ˆæ”¯æŒæŒä¹…åŒ–ï¼‰
        self.vector_store = VectorStoreManager(
            embedding_model=self.embedding,
            collection_name="amicro_simple",
            persist_directory="./simple_rag_db"  # æŒä¹…åŒ–ç›®å½•
        )
        
        # å¢é‡æ–‡æ¡£å¤„ç†å™¨ - ç”¨äºç›‘æ§æ–‡æ¡£å˜æ›´
        self.incremental_processor = None
        self._setup_incremental_processor()
        
        # æ³¨æ„ï¼šæ··åˆæ£€ç´¢å™¨å°†åœ¨çŸ¥è¯†åº“æ„å»ºå®Œæˆååˆå§‹åŒ–
        self.hybrid_retriever = None
    
    def _setup_incremental_processor(self):
        """è®¾ç½®å¢é‡æ–‡æ¡£å¤„ç†å™¨"""
        docs_folder = Path("docs")
        if docs_folder.exists() and docs_folder.is_dir():
            try:
                self.incremental_processor = IncrementalDocumentProcessor.create_with_vector_store(
                    docs_path=str(docs_folder),
                    vector_store_manager=self.vector_store,
                    chunk_size=300,  # ä¸knowledge baseæ„å»ºä¿æŒä¸€è‡´
                    chunk_overlap=50,
                    supported_extensions=['.txt', '.md', '.pdf', '.doc', '.docx']
                )
                print("ğŸ”„ å¢é‡å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸï¼Œç›‘æ§docsæ–‡ä»¶å¤¹å˜æ›´")
            except Exception as e:
                print(f"âš ï¸ å¢é‡å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                self.incremental_processor = None
        else:
            print("â„¹ï¸ æœªå‘ç°docsæ–‡ä»¶å¤¹ï¼Œè·³è¿‡å¢é‡å¤„ç†å™¨è®¾ç½®")
    
    def _build_knowledge_base(self):
        """æ„å»ºçŸ¥è¯†åº“"""
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æŒä¹…åŒ–çš„å‘é‡åº“
        if self.vector_store.is_persistent() and len(self.vector_store) > 0:
            print(f"ğŸ”„ å‘ç°å·²æœ‰æŒä¹…åŒ–å‘é‡åº“ï¼Œå…± {len(self.vector_store)} ä¸ªæ–‡æ¡£å—")
            print(f"âš¡ è·³è¿‡æ–‡æ¡£å¤„ç†ï¼Œç›´æ¥åŠ è½½ç°æœ‰å‘é‡åº“")
            # å³ä½¿ä»æŒä¹…åŒ–åŠ è½½ï¼Œä¹Ÿéœ€è¦åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨
            self._setup_hybrid_retriever()
            return
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨docsæ–‡ä»¶å¤¹
        import os
        from langchain_core.documents import Document
        
        docs_folder = Path("RAG/docs")
        if docs_folder.exists() and any(docs_folder.glob("*.txt")):
            print(f"ğŸ“š å‘ç°docsæ–‡ä»¶å¤¹ï¼ŒåŠ è½½ç« èŠ‚æ–‡æ¡£...")
            documents = []
            
            # åŠ è½½æ‰€æœ‰txtæ–‡ä»¶
            for file_path in sorted(docs_folder.glob("*.txt")):
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read().strip()
                    
                    if content:
                        doc = Document(
                            page_content=content,
                            metadata={
                                'source': str(file_path),
                                'filename': file_path.name,
                                'chapter': file_path.stem  # æ–‡ä»¶åä½œä¸ºç« èŠ‚
                            }
                        )
                        documents.append(doc)
                        
                except Exception as e:
                    print(f"âš ï¸ è¯»å–æ–‡ä»¶å¤±è´¥ {file_path.name}: {e}")
            
            print(f"ğŸ“„ æˆåŠŸåŠ è½½ {len(documents)} ä¸ªç« èŠ‚æ–‡æ¡£")
            total_chars = sum(len(doc.page_content) for doc in documents)
            print(f"ğŸ“ æ€»å­—ç¬¦æ•°: {total_chars:,}")
            
        else:
            # é™çº§åˆ°å•æ–‡ä»¶æ¨¡å¼
            print(f"ğŸ“š å¤„ç†å•æ–‡æ¡£: {self.document_path}")
            with open(self.document_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            documents = [Document(
                page_content=content,
                metadata={'source': self.document_path}
            )]
            print(f"ğŸ“„ æ–‡æ¡£åŠ è½½å®Œæˆï¼Œé•¿åº¦: {len(content)} å­—ç¬¦")
        
        # ä½¿ç”¨è¯­ä¹‰åˆ†å—æ·»åŠ åˆ°å‘é‡å­˜å‚¨
        self.vector_store.create_from_documents(
            documents,
            chunk_size=300,  # ä½¿ç”¨æ›´å°çš„å—ä»¥é€‚åº”è¯­ä¹‰åˆ†å—
            chunk_overlap=50
        )
        
        print(f"ğŸ’¾ çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼Œå…± {len(self.vector_store)} ä¸ªæ–‡æ¡£å—")
        
        # åœ¨çŸ¥è¯†åº“æ„å»ºå®Œæˆååˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨
        self._setup_hybrid_retriever()
    
    def _setup_rag_chain(self):
        """è®¾ç½®RAGé“¾"""
        # åˆ›å»ºæ£€ç´¢å™¨
        retriever = self.vector_store._create_retriever(
            search_type="similarity",
            search_kwargs={"k":8}
        )
        #ä½ æ˜¯ä¸€å¾®åŠå¯¼ä½“å…¬å¸çš„æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚
        # RAGæç¤ºæ¨¡æ¿
        prompt = PromptTemplate(
            template="""ä½ æ˜¯ä¸€ä¸ªç†Ÿè¯»çº¢æ¥¼æ¢¦çš„æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

æ–‡æ¡£å†…å®¹ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·åŸºäºæ–‡æ¡£å†…å®¹å‡†ç¡®å›ç­”ï¼ŒåŒæ—¶ç”¨ç®€çŸ­çš„å‡ å¥è¯è¯´æ˜ä½ çš„ä¾æ®ã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯è¯·è¯´æ˜ã€‚

å›ç­”ï¼š""",
            input_variables=["context", "question"]
        )
        
        # æ ¼å¼åŒ–æ–‡æ¡£
        def format_docs(docs):
            return "\n\n".join(doc.page_content for doc in docs)
        
        # æ„å»ºRAGé“¾
        self.rag_chain = (
            {"context": retriever | format_docs, "question": RunnablePassthrough()}
            | prompt
            | self.llm
            | StrOutputParser()
        )
    
    def query(self, question: str, show_sources: bool = False) -> Dict[str, Any]:
        """æŸ¥è¯¢RAGç³»ç»Ÿ"""
        print(f"â“ æŸ¥è¯¢: {question}")
        total_start_time = time.time()
        
        # æ€§èƒ½ç»Ÿè®¡å­—å…¸
        performance_stats = {}
        
        try:
            # 1. æ··åˆæ£€ç´¢é˜¶æ®µ
            print(f"ğŸ” å¼€å§‹æ··åˆæ£€ç´¢...")
            retrieval_start = time.time()
            
            if self.hybrid_retriever:
                # ä½¿ç”¨æ··åˆæ£€ç´¢ (å‘é‡ + BM25 + RRF)
                hybrid_results = self.hybrid_retriever.hybrid_search(
                    query=question,
                    k=8,                  # æœ€ç»ˆè¿”å›5ä¸ªæ–‡æ¡£
                    vector_weight=0.6,    # å‘é‡æ£€ç´¢æƒé‡
                    bm25_weight=0.4,      # BM25æ£€ç´¢æƒé‡
                    vector_k=10,          # å‘é‡æ£€ç´¢è¿”å›10ä¸ªå€™é€‰
                    bm25_k=10             # BM25æ£€ç´¢è¿”å›10ä¸ªå€™é€‰
                )
                # æå–æ–‡æ¡£ï¼ˆå¿½ç•¥RRFåˆ†æ•°ï¼‰
                retrieved_docs = [doc for doc, score in hybrid_results]
            else:
                # é™çº§åˆ°åŸºç¡€å‘é‡æ£€ç´¢
                print("âš ï¸ æ··åˆæ£€ç´¢å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€å‘é‡æ£€ç´¢")
                retriever = self.vector_store._create_retriever(
                    search_type="similarity",
                    search_kwargs={"k":8}
                )
                retrieved_docs = retriever.invoke(question)
            
            retrieval_time = time.time() - retrieval_start
            performance_stats["retrieval_time"] = retrieval_time
            print(f"ğŸ“š æ··åˆæ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ°{len(retrieved_docs)}ä¸ªç›¸å…³æ–‡æ¡£ï¼Œè€—æ—¶: {retrieval_time:.2f}ç§’")
            
            # 2. æ–‡æ¡£åå¤„ç†é˜¶æ®µ
            print(f"ğŸ“Š æ–‡æ¡£åå¤„ç†...")
            rerank_start = time.time()
            
            # ç¡®ä¿ä¸è¶…è¿‡5ä¸ªæ–‡æ¡£
            retrieved_docs = retrieved_docs[:8]
            print(f"âœ… æœ€ç»ˆä½¿ç”¨{len(retrieved_docs)}ä¸ªæ–‡æ¡£")
            
            rerank_time = time.time() - rerank_start
            performance_stats["rerank_time"] = rerank_time
            print(f"ğŸ“Š åå¤„ç†è€—æ—¶: {rerank_time:.2f}ç§’")
            
            # 3. æ–‡æ¡£æ ¼å¼åŒ–é˜¶æ®µ
            print(f"ğŸ“ å¼€å§‹æ–‡æ¡£æ ¼å¼åŒ–...")
            format_start = time.time()
            
            def format_docs(docs):
                return "\n\n".join(doc.page_content for doc in docs)
            
            context = format_docs(retrieved_docs)
            format_time = time.time() - format_start
            performance_stats["format_time"] = format_time
            print(f"ğŸ“„ æ–‡æ¡£æ ¼å¼åŒ–å®Œæˆï¼Œä¸Šä¸‹æ–‡é•¿åº¦: {len(context)}å­—ç¬¦ï¼Œè€—æ—¶: {format_time:.2f}ç§’")
            
            # 4. æç¤ºè¯ç»„è£…é˜¶æ®µ
            print(f"ğŸ”§ å¼€å§‹æç¤ºè¯ç»„è£…...")
            prompt_start = time.time()
            
            # RAGæç¤ºæ¨¡æ¿
            prompt = PromptTemplate(
                template="""ä½ æ˜¯ä¸€ä¸ªç†Ÿè¯»çº¢æ¥¼æ¢¦çš„æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

æ–‡æ¡£å†…å®¹ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·åŸºäºæ–‡æ¡£å†…å®¹å‡†ç¡®å›ç­”ï¼ŒåŒæ—¶ç”¨ç®€çŸ­çš„å‡ å¥è¯è¯´æ˜ä½ çš„ä¾æ®ã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯è¯·è¯´æ˜ã€‚

å›ç­”ï¼š""",
                input_variables=["context", "question"]
            )
            
            final_prompt = prompt.format(context=context, question=question)
            prompt_time = time.time() - prompt_start
            performance_stats["prompt_time"] = prompt_time
            print(f"ğŸ”§ æç¤ºè¯ç»„è£…å®Œæˆï¼Œæœ€ç»ˆæç¤ºé•¿åº¦: {len(final_prompt)}å­—ç¬¦ï¼Œè€—æ—¶: {prompt_time:.2f}ç§’")
            
            # 5. LLMæ¨ç†é˜¶æ®µ
            print(f"ğŸ¤– å¼€å§‹LLMæ¨ç†...")
            llm_start = time.time()
            
            answer = self.llm.invoke(final_prompt)
            
            llm_time = time.time() - llm_start
            performance_stats["llm_time"] = llm_time
            print(f"ğŸ¤– LLMæ¨ç†å®Œæˆï¼Œå›ç­”é•¿åº¦: {len(str(answer))}å­—ç¬¦ï¼Œè€—æ—¶: {llm_time:.2f}ç§’")
            
            # 6. æ¥æºè·å–é˜¶æ®µï¼ˆå¯é€‰ï¼‰
            sources = []
            source_time = 0
            if show_sources:
                print(f"ğŸ“š å¼€å§‹è·å–æ¥æºæ–‡æ¡£...")
                source_start = time.time()
                sources = self.vector_store.search_similarity(question, k=5)
                source_time = time.time() - source_start
                print(f"ğŸ“š æ¥æºè·å–å®Œæˆï¼Œè·å¾—{len(sources)}ä¸ªæ¥æºï¼Œè€—æ—¶: {source_time:.2f}ç§’")
            
            performance_stats["source_time"] = source_time
            
            # è®¡ç®—æ€»è€—æ—¶
            total_time = time.time() - total_start_time
            performance_stats["total_time"] = total_time
            
            # æ‰“å°æ€§èƒ½ç»Ÿè®¡
            print(f"\nğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
            print(f"  ğŸ” æ··åˆæ£€ç´¢: {retrieval_time:.2f}ç§’ ({retrieval_time/total_time*100:.1f}%)")
            print(f"  ğŸ“Š åå¤„ç†: {rerank_time:.2f}ç§’ ({rerank_time/total_time*100:.1f}%)")
            print(f"  ğŸ“ æ–‡æ¡£æ ¼å¼åŒ–: {format_time:.2f}ç§’ ({format_time/total_time*100:.1f}%)")
            print(f"  ğŸ”§ æç¤ºè¯ç»„è£…: {prompt_time:.2f}ç§’ ({prompt_time/total_time*100:.1f}%)")
            print(f"  ğŸ¤– LLMæ¨ç†: {llm_time:.2f}ç§’ ({llm_time/total_time*100:.1f}%)")
            if show_sources:
                print(f"  ğŸ“š æ¥æºè·å–: {source_time:.2f}ç§’ ({source_time/total_time*100:.1f}%)")
            print(f"  â±ï¸ æ€»è€—æ—¶: {total_time:.2f}ç§’")
            
            # æ‰¾å‡ºæœ€è€—æ—¶çš„ç¯èŠ‚
            time_stages = {
                #"å‘é‡æ£€ç´¢": retrieval_time,
                #"æ–‡æ¡£ç­›é€‰": rerank_time, 
                "æ··åˆæ£€ç´¢": retrieval_time,
                "åå¤„ç†": rerank_time, 
                "LLMæ¨ç†": llm_time,
                "å…¶ä»–": format_time + prompt_time + source_time
            }
            max_stage = max(time_stages.items(), key=lambda x: x[1])
            print(f"  ğŸ¯ æœ€è€—æ—¶ç¯èŠ‚: {max_stage[0]}")
            
            result = {
                "question": question,
                "answer": answer,
                "response_time": f"{total_time:.2f}ç§’",
                "performance_stats": {
                    #"retrieval_time": f"{retrieval_time:.2f}ç§’",
                    #"filter_time": f"{rerank_time:.2f}ç§’",
                    "hybrid_retrieval_time": f"{retrieval_time:.2f}ç§’",
                    "post_process_time": f"{rerank_time:.2f}ç§’",
                    "format_time": f"{format_time:.2f}ç§’", 
                    "prompt_time": f"{prompt_time:.2f}ç§’",
                    "llm_time": f"{llm_time:.2f}ç§’",
                    "source_time": f"{source_time:.2f}ç§’",
                    "total_time": f"{total_time:.2f}ç§’",
                    "bottleneck": max_stage[0]
                },
                "sources": [{"content": doc.page_content[:200] + "...", 
                           "chunk_id": doc.metadata.get("chunk_id")} 
                          for doc in sources] if show_sources else []
            }
            
            print(f"âœ… æŸ¥è¯¢å®Œæˆï¼")
            return result
            
        except Exception as e:
            error_time = time.time() - total_start_time
            print(f"âŒ æŸ¥è¯¢å‡ºé”™ï¼Œæ€»è€—æ—¶: {error_time:.2f}ç§’")
            return {
                "question": question,
                "answer": f"æŠ±æ­‰ï¼Œå¤„ç†é—®é¢˜æ—¶å‡ºé”™: {str(e)}",
                "error": str(e),
                "response_time": f"{error_time:.2f}ç§’",
                "performance_stats": {"error": True}
            }
    
    
    def interactive(self):
        """äº¤äº’æ¨¡å¼"""
        print("\n" + "="*60)
        print("ğŸ’¬ äº¤äº’æ¨¡å¼")
        print("ğŸ“ å‘½ä»¤è¯´æ˜:")
        print("  - ç›´æ¥è¾“å…¥é—®é¢˜è¿›è¡ŒæŸ¥è¯¢")
        print("  - '/update' - æ£€æŸ¥å¹¶æ›´æ–°æ–‡æ¡£")
        print("  - '/status' - æŸ¥çœ‹æ–‡æ¡£åº“çŠ¶æ€")
        print("  - '/help' - æ˜¾ç¤ºå¸®åŠ©")
        print("  - 'quit' - é€€å‡º")
        print("="*60)
        
        while True:
            try:
                user_input = input("\nğŸ¤” è¯·è¾“å…¥é—®é¢˜æˆ–å‘½ä»¤: ").strip()
                
                if not user_input:
                    continue
                    
                if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                
                # å¤„ç†å‘½ä»¤
                if user_input.startswith('/'):
                    command = user_input[1:].lower()
                    
                    if command == 'update':
                        print("ğŸ”„ æ‰§è¡Œå¢é‡æ–‡æ¡£æ›´æ–°...")
                        update_result = self.update_documents()
                        print(f"ğŸ“Š æ›´æ–°ç»“æœ: {update_result['message']}")
                        if update_result['status'] == 'success':
                            print(f"ğŸ“ˆ å¤„ç†ç»Ÿè®¡: æ–°å¢{update_result.get('new_files', 0)}ä¸ªï¼Œä¿®æ”¹{update_result.get('modified_files', 0)}ä¸ªæ–‡ä»¶")
                    
                    elif command == 'status':
                        print("ğŸ“Š æ–‡æ¡£åº“çŠ¶æ€:")
                        status = self.get_docs_status()
                        for key, value in status.items():
                            print(f"  ğŸ“Œ {key}: {value}")
                    
                    elif command == 'help':
                        print("ğŸ“– å¯ç”¨å‘½ä»¤:")
                        print("  /update - æ£€æŸ¥å¹¶æ›´æ–°docsæ–‡ä»¶å¤¹ä¸­çš„æ–‡æ¡£")
                        print("  /status - æŸ¥çœ‹å½“å‰æ–‡æ¡£åº“çŠ¶æ€")
                        print("  /help   - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯")
                        print("  quit    - é€€å‡ºç¨‹åº")
                        print("\nğŸ’¡ æç¤º: å°†æ–‡æ¡£æ”¾åœ¨ RAG/docs/ æ–‡ä»¶å¤¹ä¸­å¯ä»¥ä½¿ç”¨å¢é‡æ›´æ–°åŠŸèƒ½")
                    
                    else:
                        print(f"â“ æœªçŸ¥å‘½ä»¤: {command}ï¼Œè¾“å…¥ '/help' æŸ¥çœ‹å¸®åŠ©")
                    
                    continue
                
                # æ­£å¸¸é—®ç­”
                result = self.query(user_input, show_sources=True)
                print(f"\nğŸ’¬ å›ç­”:\n{result['answer'].content}")
                print(f"\nâ±ï¸ è€—æ—¶: {result['response_time']}")
                
                # æ˜¾ç¤ºæ¥æº
                if result['sources']:
                    print(f"\nğŸ“š ç›¸å…³æ–‡æ¡£ç‰‡æ®µ:")
                    for i, source in enumerate(result['sources'], 1):
                        print(f"  {i}. {source['content']}")
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ å†è§ï¼")
                break
            except Exception as e:
                print(f"âŒ é”™è¯¯: {e}")
    
    def update_documents(self) -> Dict[str, Any]:
        """
        è§¦å‘å¢é‡æ–‡æ¡£æ›´æ–°ï¼ˆç®€å•æ¥å£ï¼‰
        """
        if not self.incremental_processor:
            return {
                "status": "error",
                "message": "å¢é‡å¤„ç†å™¨æœªåˆå§‹åŒ–ï¼Œè¯·ç¡®ä¿docsæ–‡ä»¶å¤¹å­˜åœ¨"
            }
        
        # è°ƒç”¨å¢é‡å¤„ç†å™¨çš„æ–¹æ³•
        result = self.incremental_processor.update_documents()
        
        # å¦‚æœæœ‰æ–‡æ¡£æ›´æ–°ï¼Œé‡æ–°åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨
        if result.get("status") == "success" and result.get("total_processed", 0) > 0:
            self._refresh_hybrid_retriever()
        
        return result
    
    def get_docs_status(self) -> Dict[str, Any]:
        """
        è·å–æ–‡æ¡£åº“çŠ¶æ€ä¿¡æ¯ï¼ˆç®€å•æ¥å£ï¼‰
        """
        base_status = {
            "vector_store_size": len(self.vector_store),
            "incremental_processor_available": self.incremental_processor is not None,
            "hybrid_retriever_available": self.hybrid_retriever is not None,
        }
        
        if self.incremental_processor:
            incremental_status = self.incremental_processor.get_comprehensive_status()
            base_status.update(incremental_status)
        
        return base_status
    
    def _setup_hybrid_retriever(self):
        """åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨ï¼ˆåœ¨å‘é‡åº“æœ‰æ•°æ®åï¼‰"""
        try:
            print("ğŸ”„ åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨...")
            # ä½¿ç”¨æ›´å®½æ¾çš„BM25åŒ¹é…æ¡ä»¶
            self.hybrid_retriever = HybridRetriever(
                self.vector_store,
                bm25_min_match_ratio=0.2,  # é™ä½åˆ°20%çš„è¯åŒ¹é…å³å¯
                bm25_score_threshold=0.001  # é™ä½åˆ†æ•°é˜ˆå€¼
            )
            print("âœ… æ··åˆæ£€ç´¢å™¨åˆå§‹åŒ–æˆåŠŸ (å‘é‡æ£€ç´¢ + BM25 + RRF)")
        except Exception as e:
            print(f"âš ï¸ æ··åˆæ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            print("âš ï¸ å°†ä½¿ç”¨åŸºç¡€å‘é‡æ£€ç´¢æ¨¡å¼")
            self.hybrid_retriever = None
    
    def _refresh_hybrid_retriever(self):
        """é‡æ–°åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨ï¼ˆç”¨äºå¢é‡æ›´æ–°åï¼‰"""
        print("ğŸ”„ é‡æ–°åˆå§‹åŒ–æ··åˆæ£€ç´¢å™¨ï¼ˆå¢é‡æ›´æ–°åï¼‰...")
        self._setup_hybrid_retriever()
    
    def _start_auto_update_thread(self):
        """å¯åŠ¨è‡ªåŠ¨æ›´æ–°åå°çº¿ç¨‹"""
        if self._auto_update_thread is None or not self._auto_update_thread.is_alive():
            self._stop_auto_update.clear()
            self._auto_update_thread = threading.Thread(
                target=self._auto_update_worker,
                daemon=True,
                name="AutoUpdateThread"
            )
            self._auto_update_thread.start()
            print(f"ğŸ”„ è‡ªåŠ¨æ›´æ–°çº¿ç¨‹å·²å¯åŠ¨")
    
    def _auto_update_worker(self):
        """è‡ªåŠ¨æ›´æ–°å·¥ä½œçº¿ç¨‹"""
        while not self._stop_auto_update.is_set():
            try:
                # ç­‰å¾…5åˆ†é’Ÿï¼Œå¦‚æœæ”¶åˆ°åœæ­¢ä¿¡å·åˆ™ç«‹å³é€€å‡º
                if self._stop_auto_update.wait(timeout=300):  # 5åˆ†é’Ÿ
                    break
                
                # æ‰§è¡Œæ›´æ–°æ£€æŸ¥
                result = self.update_documents()
                
                if result["status"] == "success" and result.get("total_processed", 0) > 0:
                    total_processed = result.get("total_processed", 0)
                    new_files = result.get("new_files", 0)
                    modified_files = result.get("modified_files", 0)
                    print(f"ğŸ‰ è‡ªåŠ¨æ›´æ–°å®Œæˆ: æ–°å¢{new_files}ä¸ªæ–‡ä»¶ï¼Œä¿®æ”¹{modified_files}ä¸ªæ–‡ä»¶ï¼Œå¤„ç†{total_processed}ä¸ªæ–‡æ¡£å—")
                
                # æ— å˜æ›´æ—¶é™é»˜å¤„ç†ï¼Œä¸æ‰“å°æ—¥å¿—
                    
            except Exception as e:
                print(f"âŒ è‡ªåŠ¨æ›´æ–°å‡ºé”™: {e}")
                # å‡ºé”™åç­‰å¾…1åˆ†é’Ÿå†ç»§ç»­
                if self._stop_auto_update.wait(timeout=60):
                    break
    
    def stop_auto_update(self):
        """åœæ­¢è‡ªåŠ¨æ›´æ–°"""
        if self._auto_update_thread and self._auto_update_thread.is_alive():
            self._stop_auto_update.set()
            self._auto_update_thread.join(timeout=5)
    
    def __del__(self):
        """ææ„æ—¶ç¡®ä¿è‡ªåŠ¨æ›´æ–°çº¿ç¨‹åœæ­¢"""
        try:
            if hasattr(self, '_stop_auto_update'):
                self.stop_auto_update()
        except:
            pass

def main():
    """ä¸»å‡½æ•°"""
    rag = None
    try:
        # åˆå§‹åŒ–RAGç³»ç»Ÿ
        rag = SimpleRAG("docs/1.txt")
        rag.interactive()
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ æ”¶åˆ°é€€å‡ºä¿¡å·...")
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿé”™è¯¯: {e}")
    finally:
        # ç¡®ä¿åœæ­¢è‡ªåŠ¨æ›´æ–°çº¿ç¨‹
        if rag:
            rag.stop_auto_update()
        print("ğŸ‘‹ ç¨‹åºå·²é€€å‡º")

if __name__ == "__main__":
    main() 