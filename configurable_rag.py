#!/usr/bin/env python3
"""
å¯é…ç½®RAGç³»ç»Ÿ
æ”¯æŒå¤šç§æ£€ç´¢ç­–ç•¥çš„çµæ´»ç»„åˆ
"""

import os
os.environ['TRANSFORMERS_OFFLINE'] = '0'
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
import time
from typing import Dict, Any, List, Optional
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough

# å¯¼å…¥ç°æœ‰ç»„ä»¶
from document_loader.local_document_processor import LocalDocumentProcessor
from embedding.adapter import EmbeddingAdapter
# from embedding.reranker import AdaptiveReranker  # å·²ç¦ç”¨é‡æ’åº
from llm.adapter import LLMAdapter
from vector_store.vector_store import VectorStoreManager
from vector_store.configurable_retriever import ConfigurableRetriever

# å¯¼å…¥é…ç½®æ¨¡å—
from retrieval_config import RetrievalConfig, get_config, list_configs

# åŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv()


class ConfigurableRAG:
    """å¯é…ç½®RAGç³»ç»Ÿ"""
    
    def __init__(self, document_path: str = "2.txt", retrieval_config: str = "comprehensive"):
        """
        åˆå§‹åŒ–å¯é…ç½®RAGç³»ç»Ÿ
        
        Args:
            document_path: æ–‡æ¡£è·¯å¾„
            retrieval_config: æ£€ç´¢é…ç½®åç§°æˆ–RetrievalConfigå¯¹è±¡
        """
        # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œå°è¯•åœ¨è„šæœ¬æ‰€åœ¨ç›®å½•æŸ¥æ‰¾
        if not os.path.isabs(document_path):
            script_dir = os.path.dirname(os.path.abspath(__file__))
            full_path = os.path.join(script_dir, document_path)
            if os.path.exists(full_path):
                document_path = full_path
        
        self.document_path = document_path
        
        # è®¾ç½®æ£€ç´¢é…ç½®
        if isinstance(retrieval_config, str):
            self.config = get_config(retrieval_config)
        elif isinstance(retrieval_config, RetrievalConfig):
            self.config = retrieval_config
        else:
            raise ValueError("retrieval_config å¿…é¡»æ˜¯é…ç½®åç§°å­—ç¬¦ä¸²æˆ–RetrievalConfigå¯¹è±¡")
        
        print(f"ğŸš€ åˆå§‹åŒ–å¯é…ç½®RAGç³»ç»Ÿ...")
        print(f"ğŸ“ æ–‡æ¡£è·¯å¾„: {self.document_path}")
        print(f"ğŸ” æ£€ç´¢é…ç½®: {self.config.get_description()}")
        print(f"ğŸ¯ å¯ç”¨æ–¹æ³•: {', '.join(self.config.get_enabled_methods())}")
        
        # æ£€æŸ¥æ–‡æ¡£æ˜¯å¦å­˜åœ¨
        if not os.path.exists(document_path):
            raise FileNotFoundError(f"æ–‡æ¡£æ–‡ä»¶ä¸å­˜åœ¨: {document_path}")
        
        # åˆå§‹åŒ–ç»„ä»¶
        self._setup_components()
        self._build_knowledge_base()
        self._setup_rag_chain()
        
        print(f"âœ… RAGç³»ç»Ÿå°±ç»ªï¼")
    
    def _setup_components(self):
        """è®¾ç½®ç»„ä»¶"""
        # åµŒå…¥æ¨¡å‹ - ä½¿ç”¨å¼€æºå…è´¹çš„ bge-large-zh-v1.5
        self.embedding = EmbeddingAdapter.get_embedding("bge", "BAAI/bge-large-zh-v1.5")
        
        # LLM
        self.llm = LLMAdapter.get_llm("dashscope", "qwen-turbo", temperature=0.1)
        
        # å‘é‡å­˜å‚¨ï¼ˆæ”¯æŒæŒä¹…åŒ–ï¼‰
        self.vector_store = VectorStoreManager(
            embedding_model=self.embedding,
            collection_name="configurable_rag",
            persist_directory="./configurable_rag_db"  # æŒä¹…åŒ–ç›®å½•
        )
        
        # å¯é…ç½®æ£€ç´¢å™¨
        self.retriever = None
        try:
            self.retriever = ConfigurableRetriever(self.vector_store, self.config)
            print("âœ… å¯é…ç½®æ£€ç´¢å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ å¯é…ç½®æ£€ç´¢å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            print("âš ï¸ å°†ä½¿ç”¨åŸºç¡€å‘é‡æ£€ç´¢æ¨¡å¼")
    
    def _build_knowledge_base(self):
        """æ„å»ºçŸ¥è¯†åº“"""
        print(f"ğŸ“š å¤„ç†æ–‡æ¡£: {self.document_path}")
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æŒä¹…åŒ–çš„å‘é‡åº“
        if self.vector_store.is_persistent() and len(self.vector_store) > 0:
            print(f"ğŸ”„ å‘ç°å·²æœ‰æŒä¹…åŒ–å‘é‡åº“ï¼Œå…± {len(self.vector_store)} ä¸ªæ–‡æ¡£å—")
            print(f"âš¡ è·³è¿‡æ–‡æ¡£å¤„ç†ï¼Œç›´æ¥åŠ è½½ç°æœ‰å‘é‡åº“")
            return
        
        # ç›´æ¥è¯»å–å•ä¸ªæ–‡ä»¶
        with open(self.document_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # åˆ›å»ºæ–‡æ¡£å¯¹è±¡
        from langchain_core.documents import Document
        document = Document(
            page_content=content,
            metadata={'source': self.document_path}
        )
        
        print(f"ğŸ“„ æ–‡æ¡£åŠ è½½å®Œæˆï¼Œé•¿åº¦: {len(content)} å­—ç¬¦")
        
        # æ·»åŠ åˆ°å‘é‡å­˜å‚¨ï¼ˆè‡ªåŠ¨åˆ†å—ï¼‰
        self.vector_store.create_from_documents(
            [document],
            chunk_size=1024,
            chunk_overlap=100
        )
        
        print(f"ğŸ’¾ çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼Œå…± {len(self.vector_store)} ä¸ªæ–‡æ¡£å—")
    
    def _setup_rag_chain(self):
        """è®¾ç½®RAGé“¾"""
        # åˆ›å»ºåŸºç¡€æ£€ç´¢å™¨ä½œä¸ºå¤‡ç”¨
        self.fallback_retriever = self.vector_store._create_retriever(
            search_type="similarity",
            search_kwargs={"k": 5}
        )
        
        # RAGæç¤ºæ¨¡æ¿
        self.prompt_template = PromptTemplate(
            template="""ä½ æ˜¯ä¸€ä¸ªç†Ÿè¯»çº¢æ¥¼æ¢¦çš„æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹æ–‡æ¡£å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚

æ–‡æ¡£å†…å®¹ï¼ˆå¯èƒ½åŒ…å«å°è¯´æƒ…èŠ‚å’Œäººç‰©ä¿¡æ¯ï¼‰ï¼š
{context}

ç”¨æˆ·é—®é¢˜ï¼š{question}

è¯·åŸºäºæ–‡æ¡£å†…å®¹å‡†ç¡®å›ç­”ã€‚å¦‚æœæ–‡æ¡£ä¸­åŒ…å«å…·ä½“çš„äººç‰©ä¿¡æ¯ï¼ˆå¦‚å§“åã€å¹´é¾„ã€èŒä½ç­‰ï¼‰ï¼Œè¯·ä¼˜å…ˆä½¿ç”¨è¿™äº›å‡†ç¡®ä¿¡æ¯ã€‚å¦‚æœæ–‡æ¡£ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯è¯·è¯´æ˜ã€‚

å›ç­”ï¼š""",
            input_variables=["context", "question"]
        )
    
    def query(self, question: str, show_sources: bool = False, show_config: bool = False) -> Dict[str, Any]:
        """æŸ¥è¯¢RAGç³»ç»Ÿ"""
        print(f"â“ æŸ¥è¯¢: {question}")
        total_start_time = time.time()
        
        # æ€§èƒ½ç»Ÿè®¡å­—å…¸
        performance_stats = {}
        
        try:
            # 1. æ£€ç´¢é˜¶æ®µ
            print(f"ğŸ” å¼€å§‹æ£€ç´¢...")
            retrieval_start = time.time()
            
            if self.retriever:
                # ä½¿ç”¨å¯é…ç½®æ£€ç´¢å™¨
                hybrid_results = self.retriever.search(question)
                retrieved_docs = [doc for doc, score in hybrid_results]
            else:
                # é™çº§åˆ°åŸºç¡€å‘é‡æ£€ç´¢
                print("âš ï¸ å¯é…ç½®æ£€ç´¢å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨åŸºç¡€å‘é‡æ£€ç´¢")
                retrieved_docs = self.fallback_retriever.invoke(question)
            
            retrieval_time = time.time() - retrieval_start
            performance_stats["retrieval_time"] = retrieval_time
            print(f"ğŸ“š æ£€ç´¢å®Œæˆï¼Œæ‰¾åˆ°{len(retrieved_docs)}ä¸ªç›¸å…³æ–‡æ¡£ï¼Œè€—æ—¶: {retrieval_time:.2f}ç§’")
            
            # 2. æ–‡æ¡£åå¤„ç†é˜¶æ®µ
            print(f"ğŸ“Š æ–‡æ¡£åå¤„ç†...")
            postprocess_start = time.time()
            
            # ç¡®ä¿ä¸è¶…è¿‡é…ç½®çš„kå€¼
            retrieved_docs = retrieved_docs[:self.config.k]
            print(f"âœ… æœ€ç»ˆä½¿ç”¨{len(retrieved_docs)}ä¸ªæ–‡æ¡£")
            
            postprocess_time = time.time() - postprocess_start
            performance_stats["postprocess_time"] = postprocess_time
            print(f"ğŸ“Š åå¤„ç†è€—æ—¶: {postprocess_time:.2f}ç§’")
            
            # 3. æ–‡æ¡£æ ¼å¼åŒ–é˜¶æ®µ
            print(f"ğŸ“ å¼€å§‹æ–‡æ¡£æ ¼å¼åŒ–...")
            format_start = time.time()
            
            def format_docs(docs):
                return "\n\n".join(doc.page_content for doc in docs)
            
            context = format_docs(retrieved_docs)
            format_time = time.time() - format_start
            performance_stats["format_time"] = format_time
            print(f"ğŸ“„ æ–‡æ¡£æ ¼å¼åŒ–å®Œæˆï¼Œä¸Šä¸‹æ–‡é•¿åº¦: {len(context)}å­—ç¬¦ï¼Œè€—æ—¶: {format_time:.2f}ç§’")
            
            # 4. æç¤ºè¯ç»„è£…é˜¶æ®µ
            print(f"ğŸ”§ å¼€å§‹æç¤ºè¯ç»„è£…...")
            prompt_start = time.time()
            
            final_prompt = self.prompt_template.format(context=context, question=question)
            prompt_time = time.time() - prompt_start
            performance_stats["prompt_time"] = prompt_time
            print(f"ğŸ”§ æç¤ºè¯ç»„è£…å®Œæˆï¼Œæœ€ç»ˆæç¤ºé•¿åº¦: {len(final_prompt)}å­—ç¬¦ï¼Œè€—æ—¶: {prompt_time:.2f}ç§’")
            
            # 5. LLMæ¨ç†é˜¶æ®µ
            print(f"ğŸ¤– å¼€å§‹LLMæ¨ç†...")
            llm_start = time.time()
            
            answer = self.llm.invoke(final_prompt)
            
            llm_time = time.time() - llm_start
            performance_stats["llm_time"] = llm_time
            print(f"ğŸ¤– LLMæ¨ç†å®Œæˆï¼Œå›ç­”é•¿åº¦: {len(str(answer))}å­—ç¬¦ï¼Œè€—æ—¶: {llm_time:.2f}ç§’")
            
            # 6. æ¥æºè·å–é˜¶æ®µï¼ˆå¯é€‰ï¼‰
            sources = []
            source_time = 0
            if show_sources:
                print(f"ğŸ“š å¼€å§‹è·å–æ¥æºæ–‡æ¡£...")
                source_start = time.time()
                sources = self.vector_store.search_similarity(question, k=5)
                source_time = time.time() - source_start
                print(f"ğŸ“š æ¥æºè·å–å®Œæˆï¼Œè·å¾—{len(sources)}ä¸ªæ¥æºï¼Œè€—æ—¶: {source_time:.2f}ç§’")
            
            performance_stats["source_time"] = source_time
            
            # è®¡ç®—æ€»è€—æ—¶
            total_time = time.time() - total_start_time
            performance_stats["total_time"] = total_time
            
            # æ‰“å°æ€§èƒ½ç»Ÿè®¡
            print(f"\nğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
            print(f"  ğŸ” æ£€ç´¢: {retrieval_time:.2f}ç§’ ({retrieval_time/total_time*100:.1f}%)")
            print(f"  ğŸ“Š åå¤„ç†: {postprocess_time:.2f}ç§’ ({postprocess_time/total_time*100:.1f}%)")
            print(f"  ğŸ“ æ–‡æ¡£æ ¼å¼åŒ–: {format_time:.2f}ç§’ ({format_time/total_time*100:.1f}%)")
            print(f"  ğŸ”§ æç¤ºè¯ç»„è£…: {prompt_time:.2f}ç§’ ({prompt_time/total_time*100:.1f}%)")
            print(f"  ğŸ¤– LLMæ¨ç†: {llm_time:.2f}ç§’ ({llm_time/total_time*100:.1f}%)")
            if show_sources:
                print(f"  ğŸ“š æ¥æºè·å–: {source_time:.2f}ç§’ ({source_time/total_time*100:.1f}%)")
            print(f"  â±ï¸ æ€»è€—æ—¶: {total_time:.2f}ç§’")
            
            # æ‰¾å‡ºæœ€è€—æ—¶çš„ç¯èŠ‚
            time_stages = {
                "æ£€ç´¢": retrieval_time,
                "åå¤„ç†": postprocess_time, 
                "LLMæ¨ç†": llm_time,
                "å…¶ä»–": format_time + prompt_time + source_time
            }
            max_stage = max(time_stages.items(), key=lambda x: x[1])
            print(f"  ğŸ¯ æœ€è€—æ—¶ç¯èŠ‚: {max_stage[0]}")
            
            # æ„å»ºè¿”å›ç»“æœ
            result = {
                "question": question,
                "answer": answer,
                "response_time": f"{total_time:.2f}ç§’",
                "performance_stats": {
                    "retrieval_time": f"{retrieval_time:.2f}ç§’",
                    "postprocess_time": f"{postprocess_time:.2f}ç§’",
                    "format_time": f"{format_time:.2f}ç§’", 
                    "prompt_time": f"{prompt_time:.2f}ç§’",
                    "llm_time": f"{llm_time:.2f}ç§’",
                    "source_time": f"{source_time:.2f}ç§’",
                    "total_time": f"{total_time:.2f}ç§’",
                    "bottleneck": max_stage[0],
                    "retrieval_mode": self.config.get_description()
                },
                "sources": [{"content": doc.page_content[:200] + "...", 
                           "chunk_id": doc.metadata.get("chunk_id"),
                           "source_type": doc.metadata.get("search_type", "unknown")} 
                          for doc in sources] if show_sources else []
            }
            
            # æ·»åŠ é…ç½®ä¿¡æ¯ï¼ˆå¯é€‰ï¼‰
            if show_config:
                result["config"] = self.retriever.get_config_summary() if self.retriever else {}
            
            print(f"âœ… æŸ¥è¯¢å®Œæˆï¼")
            return result
            
        except Exception as e:
            error_time = time.time() - total_start_time
            print(f"âŒ æŸ¥è¯¢å‡ºé”™ï¼Œæ€»è€—æ—¶: {error_time:.2f}ç§’")
            return {
                "question": question,
                "answer": f"æŠ±æ­‰ï¼Œå¤„ç†é—®é¢˜æ—¶å‡ºé”™: {str(e)}",
                "error": str(e),
                "response_time": f"{error_time:.2f}ç§’",
                "performance_stats": {"error": True}
            }
    
    def switch_config(self, new_config: str):
        """
        åˆ‡æ¢æ£€ç´¢é…ç½®
        
        Args:
            new_config: æ–°çš„é…ç½®åç§°
        """
        print(f"ğŸ”„ åˆ‡æ¢æ£€ç´¢é…ç½®: {new_config}")
        
        try:
            # è·å–æ–°é…ç½®
            self.config = get_config(new_config)
            
            # é‡æ–°åˆå§‹åŒ–æ£€ç´¢å™¨
            self.retriever = ConfigurableRetriever(self.vector_store, self.config)
            
            print(f"âœ… æ£€ç´¢é…ç½®å·²åˆ‡æ¢åˆ°: {self.config.get_description()}")
            print(f"ğŸ¯ å¯ç”¨æ–¹æ³•: {', '.join(self.config.get_enabled_methods())}")
            
        except Exception as e:
            print(f"âŒ é…ç½®åˆ‡æ¢å¤±è´¥: {e}")
    
    def list_available_configs(self):
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨é…ç½®"""
        print("ğŸ“‹ å¯ç”¨æ£€ç´¢é…ç½®:")
        configs = list_configs()
        for name, description in configs.items():
            current = " (å½“å‰)" if name == getattr(self.config, 'name', None) else ""
            print(f"  â€¢ {name}: {description}{current}")
    
    def interactive(self):
        """äº¤äº’æ¨¡å¼"""
        print("\n" + "="*70)
        print("ğŸ’¬ å¯é…ç½®RAGäº¤äº’æ¨¡å¼")
        print("="*70)
        print("å‘½ä»¤è¯´æ˜:")
        print("  - ç›´æ¥è¾“å…¥é—®é¢˜è¿›è¡ŒæŸ¥è¯¢")
        print("  - è¾“å…¥ 'config' æŸ¥çœ‹å½“å‰é…ç½®")
        print("  - è¾“å…¥ 'switch <é…ç½®å>' åˆ‡æ¢é…ç½®")
        print("  - è¾“å…¥ 'list' åˆ—å‡ºæ‰€æœ‰é…ç½®")
        print("  - è¾“å…¥ 'quit' é€€å‡º")
        print("="*70)
        
        while True:
            try:
                user_input = input(f"\nğŸ¤” è¯·è¾“å…¥ [{self.config.get_description()}]: ").strip()
                
                if not user_input:
                    continue
                    
                if user_input.lower() in ['quit', 'exit', 'é€€å‡º']:
                    print("ğŸ‘‹ å†è§ï¼")
                    break
                elif user_input.lower() == 'config':
                    print(f"ğŸ“‹ å½“å‰é…ç½®: {self.config.get_description()}")
                    print(f"ğŸ¯ å¯ç”¨æ–¹æ³•: {', '.join(self.config.get_enabled_methods())}")
                    if self.retriever:
                        config_summary = self.retriever.get_config_summary()
                        weights = config_summary.get('weights', {})
                        print(f"âš–ï¸ æƒé‡åˆ†é…: å‘é‡={weights.get('vector', 0):.2f}, BM25={weights.get('bm25', 0):.2f}, SQL={weights.get('sql', 0):.2f}")
                elif user_input.lower() == 'list':
                    self.list_available_configs()
                elif user_input.lower().startswith('switch '):
                    config_name = user_input[7:].strip()
                    if config_name:
                        self.switch_config(config_name)
                    else:
                        print("âŒ è¯·æŒ‡å®šé…ç½®åç§°ï¼Œä¾‹å¦‚: switch semantic")
                else:
                    # æ‰§è¡ŒæŸ¥è¯¢
                    result = self.query(user_input, show_sources=True, show_config=False)
                    print(f"\nğŸ’¬ å›ç­”:\n{result['answer'].content}")
                    print(f"\nâ±ï¸ è€—æ—¶: {result['response_time']}")
                    print(f"ğŸ” æ£€ç´¢æ¨¡å¼: {result['performance_stats'].get('retrieval_mode', 'unknown')}")
                    
                    # æ˜¾ç¤ºæ¥æº
                    if result['sources']:
                        print(f"\nğŸ“š ç›¸å…³æ–‡æ¡£ç‰‡æ®µ:")
                        for i, source in enumerate(result['sources'], 1):
                            source_type = source.get('source_type', 'unknown')
                            print(f"  {i}. [{source_type}] {source['content']}")
                
            except KeyboardInterrupt:
                print("\nğŸ‘‹ å†è§ï¼")
                break
            except Exception as e:
                print(f"âŒ é”™è¯¯: {e}")


def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    config_name = "comprehensive"  # é»˜è®¤é…ç½®
    if len(sys.argv) > 1:
        config_name = sys.argv[1]
    
    try:
        # æ˜¾ç¤ºå¯ç”¨é…ç½®
        print("ğŸ“‹ å¯ç”¨æ£€ç´¢é…ç½®:")
        configs = list_configs()
        for name, description in configs.items():
            print(f"  â€¢ {name}: {description}")
        print()
        
        # åˆå§‹åŒ–RAGç³»ç»Ÿ
        rag = ConfigurableRAG("2.txt", retrieval_config=config_name)
        rag.interactive()
            
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿé”™è¯¯: {e}")


if __name__ == "__main__":
    main() 