#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Quizletçˆ¬è™«ç¨‹åº
çˆ¬å–çº¢æ¥¼æ¢¦çŸ¥è¯†ç«èµ›é¢˜åº“çš„é¢˜ç›®å’Œç­”æ¡ˆ
"""

import requests
import json
import time
import re
import random
from typing import List, Dict, Any
from bs4 import BeautifulSoup
import csv
import os

class QuizletScraper:
    def __init__(self):
        """åˆå§‹åŒ–çˆ¬è™«"""
        self.session = requests.Session()
        self.setup_headers()
        
    def setup_headers(self):
        """è®¾ç½®æ›´çœŸå®çš„è¯·æ±‚å¤´"""
        user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:121.0) Gecko/20100101 Firefox/121.0'
        ]
        
        self.session.headers.update({
            'User-Agent': random.choice(user_agents),
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Sec-Fetch-User': '?1',
            'Cache-Control': 'max-age=0',
            'DNT': '1',
        })
        
    def get_page_content(self, url: str) -> str:
        """è·å–é¡µé¢å†…å®¹"""
        try:
            # æ·»åŠ éšæœºå»¶è¿Ÿ
            time.sleep(random.uniform(1, 3))
            
            response = self.session.get(url, timeout=15)
            response.raise_for_status()
            return response.text
        except requests.RequestException as e:
            print(f"è¯·æ±‚å¤±è´¥: {e}")
            return ""
    
    def extract_quizlet_data(self, html_content: str) -> List[Dict[str, str]]:
        """æå–Quizletæ•°æ®"""
        soup = BeautifulSoup(html_content, 'html.parser')
        flashcards = []
        
        # å°è¯•å¤šç§é€‰æ‹©å™¨ç­–ç•¥
        selectors = [
            # ç­–ç•¥1: æŸ¥æ‰¾ç‰¹å®šçš„Quizletç±»
            '.SetPageTerms-term',
            '.SetPageTerms-termText',
            '[data-testid="term"]',
            '[data-testid="definition"]',
            
            # ç­–ç•¥2: æŸ¥æ‰¾åŒ…å«é¢˜ç›®å’Œç­”æ¡ˆçš„å®¹å™¨
            '.SetPageTerms-termContainer',
            '.SetPageTerms-termRow',
            
            # ç­–ç•¥3: æŸ¥æ‰¾é—ªå¡ç›¸å…³å…ƒç´ 
            '[class*="card"]',
            '[class*="term"]',
            '[class*="flashcard"]',
            
            # ç­–ç•¥4: æŸ¥æ‰¾æ–‡æœ¬å†…å®¹
            'div[class*="text"]',
            'span[class*="text"]',
        ]
        
        for selector in selectors:
            elements = soup.select(selector)
            if elements:
                print(f"æ‰¾åˆ° {len(elements)} ä¸ªå…ƒç´ ï¼Œä½¿ç”¨é€‰æ‹©å™¨: {selector}")
                flashcards = self.extract_from_elements(elements)
                if flashcards:
                    break
        
        # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œå°è¯•ä»é¡µé¢æ–‡æœ¬ä¸­æå–
        if not flashcards:
            flashcards = self.extract_from_page_text(soup)
        
        return flashcards
    
    def extract_from_elements(self, elements) -> List[Dict[str, str]]:
        """ä»å…ƒç´ ä¸­æå–é¢˜ç›®å’Œç­”æ¡ˆ"""
        flashcards = []
        
        for element in elements:
            try:
                # å°è¯•æå–é¢˜ç›®å’Œç­”æ¡ˆ
                text = element.get_text(strip=True)
                if text and len(text) > 5:
                    # å°è¯•åˆ†å‰²é¢˜ç›®å’Œç­”æ¡ˆ
                    parts = text.split('\n')
                    if len(parts) >= 2:
                        question = parts[0].strip()
                        answer = parts[1].strip()
                        
                        if question and answer and question != answer:
                            flashcards.append({
                                'question': question,
                                'answer': answer
                            })
            except Exception as e:
                continue
        
        return flashcards
    
    def extract_from_page_text(self, soup) -> List[Dict[str, str]]:
        """ä»é¡µé¢æ–‡æœ¬ä¸­æå–é¢˜ç›®å’Œç­”æ¡ˆ"""
        flashcards = []
        
        try:
            # è·å–é¡µé¢æ‰€æœ‰æ–‡æœ¬
            page_text = soup.get_text()
            
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾å¯èƒ½çš„é¢˜ç›®å’Œç­”æ¡ˆæ¨¡å¼
            # æŸ¥æ‰¾åŒ…å«é—®å·æˆ–å†’å·çš„è¡Œ
            lines = page_text.split('\n')
            
            for i, line in enumerate(lines):
                line = line.strip()
                if not line or len(line) < 5:
                    continue
                
                # æŸ¥æ‰¾åŒ…å«é—®å·çš„è¡Œä½œä¸ºé¢˜ç›®
                if 'ï¼Ÿ' in line or '?' in line:
                    question = line
                    # æŸ¥æ‰¾ä¸‹ä¸€è¡Œä½œä¸ºç­”æ¡ˆ
                    if i + 1 < len(lines):
                        answer = lines[i + 1].strip()
                        if answer and len(answer) > 2:
                            flashcards.append({
                                'question': question,
                                'answer': answer
                            })
                
                # æŸ¥æ‰¾åŒ…å«å†’å·çš„è¡Œ
                elif 'ï¼š' in line or ':' in line:
                    parts = line.split('ï¼š') if 'ï¼š' in line else line.split(':')
                    if len(parts) >= 2:
                        question = parts[0].strip()
                        answer = parts[1].strip()
                        if question and answer and len(question) > 2 and len(answer) > 2:
                            flashcards.append({
                                'question': question,
                                'answer': answer
                            })
        
        except Exception as e:
            print(f"ä»é¡µé¢æ–‡æœ¬æå–æ•°æ®æ—¶å‡ºé”™: {e}")
        
        return flashcards
    
    def extract_from_api(self, url: str) -> List[Dict[str, str]]:
        """å°è¯•ä»APIè·å–æ•°æ®"""
        try:
            # æå–set ID
            set_id_match = re.search(r'/cn/(\d+)/', url)
            if not set_id_match:
                return []
            
            set_id = set_id_match.group(1)
            
            # å°è¯•è®¿é—®APIç«¯ç‚¹
            api_url = f"https://quizlet.com/webapi/3.2/sets/{set_id}/terms"
            
            # æ·»åŠ APIç‰¹å®šçš„è¯·æ±‚å¤´
            api_headers = self.session.headers.copy()
            api_headers.update({
                'Accept': 'application/json',
                'X-Requested-With': 'XMLHttpRequest',
            })
            
            response = self.session.get(api_url, headers=api_headers, timeout=10)
            if response.status_code == 200:
                data = response.json()
                flashcards = []
                
                for term in data.get('responses', [{}])[0].get('models', {}).get('term', []):
                    flashcards.append({
                        'question': term.get('word', ''),
                        'answer': term.get('definition', '')
                    })
                
                return flashcards
        except Exception as e:
            print(f"APIæå–å¤±è´¥: {e}")
        
        return []
    
    def scrape_quizlet(self, url: str) -> List[Dict[str, str]]:
        """çˆ¬å–Quizletæ•°æ®"""
        print(f"æ­£åœ¨çˆ¬å–: {url}")
        
        # é¦–å…ˆå°è¯•ä»APIè·å–æ•°æ®
        print("å°è¯•ä»APIè·å–æ•°æ®...")
        flashcards = self.extract_from_api(url)
        
        if not flashcards:
            # å¦‚æœAPIå¤±è´¥ï¼Œå°è¯•ä»HTMLæå–
            print("APIå¤±è´¥ï¼Œå°è¯•ä»HTMLæå–...")
            html_content = self.get_page_content(url)
            if html_content:
                flashcards = self.extract_quizlet_data(html_content)
        
        return flashcards
    
    def save_to_csv(self, flashcards: List[Dict[str, str]], filename: str = "quizlet_data.csv"):
        """ä¿å­˜æ•°æ®åˆ°CSVæ–‡ä»¶"""
        if not flashcards:
            print("æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
            return
        
        with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
            fieldnames = ['question', 'answer']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            writer.writeheader()
            for card in flashcards:
                writer.writerow(card)
        
        print(f"æ•°æ®å·²ä¿å­˜åˆ° {filename}")
    
    def save_to_json(self, flashcards: List[Dict[str, str]], filename: str = "quizlet_data.json"):
        """ä¿å­˜æ•°æ®åˆ°JSONæ–‡ä»¶"""
        if not flashcards:
            print("æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
            return
        
        with open(filename, 'w', encoding='utf-8') as jsonfile:
            json.dump(flashcards, jsonfile, ensure_ascii=False, indent=2)
        
        print(f"æ•°æ®å·²ä¿å­˜åˆ° {filename}")

def main():
    """ä¸»å‡½æ•°"""
    url = "https://quizlet.com/cn/274823239/%E7%BA%A2%E6%A5%BC%E6%A2%A6%E7%9F%A5%E8%AF%86%E7%AB%9E%E8%B5%9B%E9%A2%98%E5%BA%93-flash-cards/"
    
    scraper = QuizletScraper()
    
    print("ğŸ¤– Quizletçˆ¬è™«å¯åŠ¨")
    print("=" * 50)
    
    # çˆ¬å–æ•°æ®
    flashcards = scraper.scrape_quizlet(url)
    
    if flashcards:
        print(f"âœ“ æˆåŠŸçˆ¬å–åˆ° {len(flashcards)} ä¸ªé¢˜ç›®")
        
        # æ˜¾ç¤ºå‰å‡ ä¸ªé¢˜ç›®ä½œä¸ºé¢„è§ˆ
        print("\nğŸ“‹ æ•°æ®é¢„è§ˆ:")
        for i, card in enumerate(flashcards[:5]):
            print(f"{i+1}. é¢˜ç›®: {card['question']}")
            print(f"   ç­”æ¡ˆ: {card['answer']}")
            print()
        
        # ä¿å­˜æ•°æ®
        scraper.save_to_csv(flashcards)
        scraper.save_to_json(flashcards)
        
    else:
        print("âŒ æœªèƒ½çˆ¬å–åˆ°æ•°æ®")
        print("å¯èƒ½çš„åŸå› :")
        print("1. é¡µé¢éœ€è¦ç™»å½•")
        print("2. é¡µé¢ç»“æ„å‘ç”Ÿå˜åŒ–")
        print("3. ç½‘ç»œè¿æ¥é—®é¢˜")
        print("4. åçˆ¬è™«æœºåˆ¶")
        print("\nå»ºè®®:")
        print("1. å°è¯•ä½¿ç”¨Seleniumç‰ˆæœ¬: python quizlet_selenium_scraper.py")
        print("2. æ‰‹åŠ¨è®¿é—®é¡µé¢ç¡®è®¤æ˜¯å¦éœ€è¦ç™»å½•")
        print("3. æ£€æŸ¥ç½‘ç»œè¿æ¥")

if __name__ == "__main__":
    main() 